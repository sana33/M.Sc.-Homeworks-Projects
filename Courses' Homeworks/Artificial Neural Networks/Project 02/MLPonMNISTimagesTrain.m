function [weightMatrix, errorMatrix] = MLPonMNISTimagesTrain(activationFunction, ...
    activationFunctionDerivative, layersNeuronNo, mnistDB, targetValues, epochs, batchSize, learningRate, momentum, isMomentum)
    
    % The number of training vectors.    
    trainingSetSize = size(mnistDB, 2);
    % Input vector has 784 dimensions.    
    inputDimensions = size(mnistDB, 1);
    % We have to distinguish 10 digits.    
    outputDimensions = size(targetValues, 1);
    
    neuronsPerLayer = layersNeuronNo;
    hiddenLayersNo = size(neuronsPerLayer, 2) - 2;
    maxLayersNeuronNo = max(neuronsPerLayer);

    weightMatrix = rand(maxLayersNeuronNo, maxLayersNeuronNo, hiddenLayersNo + 1);
    weightMatrix(:, :, hiddenLayersNo) = weightMatrix(:, :, hiddenLayersNo) ./ inputDimensions;
    weightMatrix(:, :, hiddenLayersNo + 1) = weightMatrix(:, :, hiddenLayersNo + 1) ./ hiddenLayersNo;
    
    oldWeightMatrix = weightMatrix;
    olderWeightMatrix = weightMatrix;
    
    netInputs = zeros(batchSize, maxLayersNeuronNo, hiddenLayersNo + 1);
    actFuncOutputs = zeros(batchSize, maxLayersNeuronNo, hiddenLayersNo + 1);
    
    hiddenDelta = zeros(batchSize, maxLayersNeuronNo, hiddenLayersNo);
    outputDelta = zeros(batchSize, neuronsPerLayer(hiddenLayersNo + 2));
    
    errorMatrix = zeros(trainingSetSize / batchSize, epochs);
    
    figure; hold on; grid on;
    
    %% Training procedure
    for t = 1:epochs
        for k = 1: trainingSetSize / batchSize
            
            %% Getting the right input matrix according to the batch size
            
			inputMatrix = mnistDB(:, (k - 1) * batchSize + 1:k * batchSize);
            
            %% Calculating netInputs for all hidden and output units
            netInputs(:, 1:neuronsPerLayer(2), 1) = ...
            transpose(inputMatrix) * weightMatrix(1:neuronsPerLayer(1), 1:neuronsPerLayer(2), 1);
            actFuncOutputs(:, 1:neuronsPerLayer(2), 1) = ...
                activationFunction(netInputs(:, 1:neuronsPerLayer(2), 1));
            
            for ii = 2:hiddenLayersNo + 1
                netInputs(:, 1:neuronsPerLayer(ii + 1), ii) = ...
                    actFuncOutputs(:, 1:neuronsPerLayer(ii), ii - 1) ...
                    * weightMatrix(1:neuronsPerLayer(ii), 1:neuronsPerLayer(ii + 1), ii);
                actFuncOutputs(:, 1:neuronsPerLayer(ii + 1), ii) = ...
                    activationFunction(netInputs(:, 1:neuronsPerLayer(ii + 1), ii));                
            end
            
            %% Getting the target values
            targetVector = targetValues(:, (k - 1) * batchSize + 1:k * batchSize);

            %% Calculating the delta value for the output and hidden units
            outputDelta(:, 1:neuronsPerLayer(hiddenLayersNo + 2)) = ... 
                activationFunctionDerivative(netInputs(:, 1:neuronsPerLayer(hiddenLayersNo + 2), hiddenLayersNo + 1)) .* ...
                (transpose(targetVector) - ...
                actFuncOutputs(:, 1:neuronsPerLayer(hiddenLayersNo + 2), hiddenLayersNo + 1));
            
            hiddenDelta(:, 1:neuronsPerLayer(hiddenLayersNo + 1), hiddenLayersNo) = ...
                activationFunctionDerivative(netInputs(:, 1:neuronsPerLayer(hiddenLayersNo + 1), hiddenLayersNo)) .* ...
                (outputDelta(:, 1:neuronsPerLayer(hiddenLayersNo + 2)) * ...
                transpose(weightMatrix(1:neuronsPerLayer(hiddenLayersNo + 1), 1:neuronsPerLayer(hiddenLayersNo + 2), hiddenLayersNo + 1)));
            mm = hiddenLayersNo - 1;            
            while(mm > 0)
                hiddenDelta(:, 1:neuronsPerLayer(mm + 1), mm) = ...
                    activationFunctionDerivative(netInputs(:, 1:neuronsPerLayer(mm + 1), mm)) .* ...
                    (hiddenDelta(:, 1:neuronsPerLayer(mm + 2), mm + 1) * ...
                    transpose(weightMatrix(1:neuronsPerLayer(mm + 1), 1:neuronsPerLayer(mm + 2), mm + 1)));
                mm = mm - 1;
            end
            
            %% Updating the weight matrix for all hidden and output units
            if isMomentum
                weightMatrix(1:neuronsPerLayer(1), 1:neuronsPerLayer(2), 1) = ...
                oldWeightMatrix(1:neuronsPerLayer(1), 1:neuronsPerLayer(2), 1) + ...
                learningRate .* (inputMatrix * ...
                hiddenDelta(:, 1:neuronsPerLayer(2), 1)) + ...
                momentum * (oldWeightMatrix(1:neuronsPerLayer(1), 1:neuronsPerLayer(2), 1) - ...
                olderWeightMatrix(1:neuronsPerLayer(1), 1:neuronsPerLayer(2), 1));
                for nn = 2:hiddenLayersNo
                    weightMatrix(1:neuronsPerLayer(nn), 1:neuronsPerLayer(nn + 1), nn) = ...
                    oldWeightMatrix(1:neuronsPerLayer(nn), 1:neuronsPerLayer(nn + 1), nn) + ...
                    learningRate .* (transpose(actFuncOutputs(:, 1:neuronsPerLayer(nn), nn - 1)) * ...
                    hiddenDelta(:, 1:neuronsPerLayer(nn + 1), nn)) + ...
                    momentum * (oldWeightMatrix(1:neuronsPerLayer(nn), 1:neuronsPerLayer(nn + 1), nn) - ...
                    olderWeightMatrix(1:neuronsPerLayer(nn), 1:neuronsPerLayer(nn + 1), nn));
                end

                weightMatrix(1:neuronsPerLayer(hiddenLayersNo + 1), 1:neuronsPerLayer(hiddenLayersNo + 2), hiddenLayersNo + 1) = ...
                oldWeightMatrix(1:neuronsPerLayer(hiddenLayersNo + 1), 1:neuronsPerLayer(hiddenLayersNo + 2), hiddenLayersNo + 1) + ...
                learningRate .* (transpose(actFuncOutputs(:, 1:neuronsPerLayer(hiddenLayersNo + 1), hiddenLayersNo)) * ...
                outputDelta(:, 1:neuronsPerLayer(hiddenLayersNo + 2))) + ...
                momentum * (oldWeightMatrix(1:neuronsPerLayer(hiddenLayersNo + 1), 1:neuronsPerLayer(hiddenLayersNo + 2), hiddenLayersNo + 1) - ...
                olderWeightMatrix(1:neuronsPerLayer(hiddenLayersNo + 1), 1:neuronsPerLayer(hiddenLayersNo + 2), hiddenLayersNo + 1));
                olderWeightMatrix = oldWeightMatrix;
                oldWeightMatrix = weightMatrix;
            else                
                weightMatrix(1:neuronsPerLayer(1), 1:neuronsPerLayer(2), 1) = ...
                weightMatrix(1:neuronsPerLayer(1), 1:neuronsPerLayer(2), 1) + ...
                learningRate .* (inputMatrix * ...
                hiddenDelta(:, 1:neuronsPerLayer(2), 1));
                for nn = 2:hiddenLayersNo
                    weightMatrix(1:neuronsPerLayer(nn), 1:neuronsPerLayer(nn + 1), nn) = ...
                    weightMatrix(1:neuronsPerLayer(nn), 1:neuronsPerLayer(nn + 1), nn) + ...
                    learningRate .* (transpose(actFuncOutputs(:, 1:neuronsPerLayer(nn), nn - 1)) * ...
                    hiddenDelta(:, 1:neuronsPerLayer(nn + 1), nn));
                end

                weightMatrix(1:neuronsPerLayer(hiddenLayersNo + 1), 1:neuronsPerLayer(hiddenLayersNo + 2), hiddenLayersNo + 1) = ...
                weightMatrix(1:neuronsPerLayer(hiddenLayersNo + 1), 1:neuronsPerLayer(hiddenLayersNo + 2), hiddenLayersNo + 1) + ...
                learningRate .* (transpose(actFuncOutputs(:, 1:neuronsPerLayer(hiddenLayersNo + 1), hiddenLayersNo)) * ...
                outputDelta(:, 1:neuronsPerLayer(hiddenLayersNo + 2)));
            end
            
            %% Calculating the error values per batch size
            errorMatrix(k, t) = mean(transpose(sum((targetVector - ...
                transpose(actFuncOutputs(:, 1:neuronsPerLayer(hiddenLayersNo + 2), hiddenLayersNo + 1))) .^ 2) ./ 2));
%             errorMatrix(k, t) = mean(transpose(sqrt(sum((targetVector - ...
%                 transpose(actFuncOutputs(:, 1:neuronsPerLayer(hiddenLayersNo + 2), hiddenLayersNo + 1))) .^ 2))));

        end
        
        % Calculate the error for plotting.
        h1 = plot(mean(errorMatrix(:, 1:t)), '-r');
        drawnow;
    end
end